{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataframe from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweet_csvs/realDonaldTrump_tweets.csv', index_col = None, header = 0, \n",
    "                     parse_dates=['created_at'], infer_datetime_format = True, dayfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3378 entries, 0 to 3377\n",
      "Data columns (total 3 columns):\n",
      "id            3378 non-null int64\n",
      "created_at    3378 non-null datetime64[ns]\n",
      "text          3378 non-null object\n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 79.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>820251730407473153</td>\n",
       "      <td>2017-01-14 12:50:26</td>\n",
       "      <td>Congressman John Lewis should spend more time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>820255947956383744</td>\n",
       "      <td>2017-01-14 13:07:12</td>\n",
       "      <td>mention crime infested) rather than falsely co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id          created_at  \\\n",
       "0  820251730407473153 2017-01-14 12:50:26   \n",
       "1  820255947956383744 2017-01-14 13:07:12   \n",
       "\n",
       "                                                text  \n",
       "0  Congressman John Lewis should spend more time ...  \n",
       "1  mention crime infested) rather than falsely co...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>1014090584963866624</td>\n",
       "      <td>2018-07-03 10:16:51</td>\n",
       "      <td>Crazy Maxine Waters, said by some to be one of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>1013976609290964997</td>\n",
       "      <td>2018-07-03 02:43:57</td>\n",
       "      <td>Many Democrats are deeply concerned about the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id          created_at  \\\n",
       "3376  1014090584963866624 2018-07-03 10:16:51   \n",
       "3377  1013976609290964997 2018-07-03 02:43:57   \n",
       "\n",
       "                                                   text  \n",
       "3376  Crazy Maxine Waters, said by some to be one of...  \n",
       "3377  Many Democrats are deeply concerned about the ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_bow = CountVectorizer(ngram_range=(1, 1), stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_bow = vect_bow.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from collections import Counter\n",
    "\n",
    "# We can use the TfidfVectorizer to find ngrams for us\n",
    "vect_tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words = 'english')\n",
    "\n",
    "# Pulls all of trumps tweet text's into one giant string\n",
    "#summaries = \"\".join(df['text'])\n",
    "#ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "#Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tfidf = vect_tfidf.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test sentence\n",
    "#sentence = 'To all the little girls watching...never doubt that you are valuable and powerful & deserving of every chance & opportunity in the world.'\n",
    "test = ['Come on and kill Kenny!', \n",
    "        'Make America great again!', \n",
    "        'Beer... Beeeeer... Beeeeeeeeer... WOO-HOO!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = vect_tfidf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bow = vect_bow.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocsvm = svm.OneClassSVM(nu = 0.5, kernel = 'rbf', gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_bow = [1 for i in range(trump_bow.shape[0])]\n",
    "y_true_tfidf = [1 for i in range(trump_tfidf.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocsvm.fit(trump_bow, y = y_true_bow)\n",
    "prediction_bow = ocsvm.predict(test_bow)\n",
    "prediction_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocsvm.fit(trump_tfidf, y = y_true_tfidf)\n",
    "prediction_tfidf = ocsvm.predict(test_tfidf)\n",
    "prediction_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize, TweetTokenizer, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tok = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.6 ms, sys: 33 µs, total: 48.6 ms\n",
      "Wall time: 48.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_tweets = []\n",
    "for tweet in df_train:\n",
    "    tokenized = regexp_tok.tokenize(tweet)\n",
    "    tokenized_tweets.append(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.7 s, sys: 31.7 ms, total: 1.73 s\n",
      "Wall time: 883 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v_model = Word2Vec(tokenized_tweets, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tokenized = []\n",
    "for tweet in df_train:\n",
    "    tweet_tokenized = regexp_tok.tokenize(tweet)\n",
    "    df_train_tokenized.append(tweet_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 s, sys: 39.9 ms, total: 25.4 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wmd_list = []\n",
    "for sentence in test:\n",
    "    wmd_list_temp = []\n",
    "    for tweet in df_train_tokenized:\n",
    "        wmd = w2v_model.wv.wmdistance(tweet, regexp_tok.tokenize(sentence))\n",
    "        wmd_list_temp.append(wmd)\n",
    "    wmd_list.append(np.max(wmd_list_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.643882510278225 is a valid value\n",
      "5.8476670864133835 is a valid value\n",
      "inf is NOT a valid value\n"
     ]
    }
   ],
   "source": [
    "for i in wmd_list:\n",
    "    if np.isinf(i) == False:\n",
    "        print('{} is a valid value'.format(i))\n",
    "    else:\n",
    "        print('{} is NOT a valid value'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity & Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Come on and kill Kenny!\n",
      "Cosine similarity Bag-Of-Words: 0.267\n",
      "Cosine similarity TF-IDF: 0.327\n",
      "Mean Cosine Similarity: 0.297\n",
      "\n",
      "OneClassSVM BOW prediction: 1\n",
      "OneClassSVM TF-IDF prediction: -1\n",
      "\n",
      "Word2Vec Word Mover`s Distance: 5.643882510278225\n",
      "\n",
      ">>> Make America great again!\n",
      "Cosine similarity Bag-Of-Words: 1.0\n",
      "Cosine similarity TF-IDF: 1.0\n",
      "Mean Cosine Similarity: 1.0\n",
      "\n",
      "OneClassSVM BOW prediction: 1\n",
      "OneClassSVM TF-IDF prediction: 1\n",
      "\n",
      "Word2Vec Word Mover`s Distance: 5.8476670864133835\n",
      "\n",
      ">>> Beer... Beeeeer... Beeeeeeeeer... WOO-HOO!\n",
      "Cosine similarity Bag-Of-Words: 0.0\n",
      "Cosine similarity TF-IDF: 0.0\n",
      "Mean Cosine Similarity: 0.0\n",
      "\n",
      "OneClassSVM BOW prediction: 1\n",
      "OneClassSVM TF-IDF prediction: 1\n",
      "\n",
      "Word2Vec Word Mover`s Distance: inf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "for sentence in test:\n",
    "    sentence_bow = vect_bow.transform([sentence])\n",
    "    cos_dists_bow = cosine_similarity(trump_bow, sentence_bow)\n",
    "    \n",
    "    sentence_tfidf = vect_tfidf.transform([sentence])\n",
    "    cos_dists_tfidf = cosine_similarity(trump_tfidf, sentence_tfidf)\n",
    "    \n",
    "    mean_cos_dist = np.mean([np.max(cos_dists_bow), np.max(cos_dists_tfidf)])\n",
    "    \n",
    "    print('>>> {}'.format(sentence))\n",
    "    print('Cosine similarity Bag-Of-Words: {}'.format(round(np.max(cos_dists_bow), 3)))\n",
    "    print('Cosine similarity TF-IDF: {}'.format(round(np.max(cos_dists_tfidf), 3)))\n",
    "    print('Mean Cosine Similarity: {}\\n'.format(round(mean_cos_dist, 3)))\n",
    "    print('OneClassSVM BOW prediction: {}'.format(prediction_bow[i]))\n",
    "    print('OneClassSVM TF-IDF prediction: {}\\n'.format(prediction_tfidf[i]))\n",
    "    print('Word2Vec Word Mover`s Distance: {}\\n'.format(wmd_list[i]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w2v.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(df_train_tokenized, 'df_train_tokenized.pkl')\n",
    "\n",
    "joblib.dump(vect_bow, 'vect_bow.pkl')\n",
    "joblib.dump(trump_bow, 'trump_bow.pkl')\n",
    "\n",
    "joblib.dump(vect_tfidf, 'vect_tfidf.pkl')\n",
    "joblib.dump(trump_tfidf, 'trump_tfidf.pkl')\n",
    "\n",
    "joblib.dump(ocsvm, 'ocsvm.pkl')\n",
    "\n",
    "joblib.dump(w2v_model, 'w2v.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
